{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from medmnist.dataset import MedMNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = ['tissuemnist', 'octmnist', 'organamnist']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from medmnist import INFO\n",
    "\n",
    "infos = [INFO[dataset] for dataset in datasets]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'python_class': 'TissueMNIST',\n",
       " 'description': 'We use the BBBC051, available from the Broad Bioimage Benchmark Collection. The dataset contains 236,386 human kidney cortex cells, segmented from 3 reference tissue specimens and organized into 8 categories. We split the source dataset with a ratio of 7:1:2 into training, validation and test set. Each gray-scale image is 32×32×7 pixels, where 7 denotes 7 slices. We take maximum values across the slices and resize them into 28×28 gray-scale images.',\n",
       " 'url': 'https://zenodo.org/records/10519652/files/tissuemnist.npz?download=1',\n",
       " 'MD5': 'ebe78ee8b05294063de985d821c1c34b',\n",
       " 'url_64': 'https://zenodo.org/records/10519652/files/tissuemnist_64.npz?download=1',\n",
       " 'MD5_64': '123ece2eba09d0aa5d698fda57103344',\n",
       " 'url_128': 'https://zenodo.org/records/10519652/files/tissuemnist_128.npz?download=1',\n",
       " 'MD5_128': '61b955355d7425a89687b06cca3ce0c2',\n",
       " 'url_224': 'https://zenodo.org/records/10519652/files/tissuemnist_224.npz?download=1',\n",
       " 'MD5_224': 'b077128c4a949f0a4eb01517f9037b9c',\n",
       " 'task': 'multi-class',\n",
       " 'label': {'0': 'Collecting Duct, Connecting Tubule',\n",
       "  '1': 'Distal Convoluted Tubule',\n",
       "  '2': 'Glomerular endothelial cells',\n",
       "  '3': 'Interstitial endothelial cells',\n",
       "  '4': 'Leukocytes',\n",
       "  '5': 'Podocytes',\n",
       "  '6': 'Proximal Tubule Segments',\n",
       "  '7': 'Thick Ascending Limb'},\n",
       " 'n_channels': 1,\n",
       " 'n_samples': {'train': 165466, 'val': 23640, 'test': 47280},\n",
       " 'license': 'CC BY 4.0'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "infos[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import medmnist\n",
    "\n",
    "assert all(info['n_channels'] == infos[0]['n_channels'] for info in infos)\n",
    "DataClasses = [getattr(medmnist.dataset, info['python_class']) for info in infos]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_size = 28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "\n",
    "\n",
    "def default_transform():\n",
    "    return transforms.Compose(\n",
    "            [\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize(mean=(0.5,), std=(0.5,)),\n",
    "            ]\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using downloaded and verified file: C:\\Users\\pasca\\.medmnist\\tissuemnist.npz\n",
      "Using downloaded and verified file: C:\\Users\\pasca\\.medmnist\\octmnist.npz\n",
      "Using downloaded and verified file: C:\\Users\\pasca\\.medmnist\\organamnist.npz\n"
     ]
    }
   ],
   "source": [
    "train_sets = []\n",
    "for DataClass in DataClasses:\n",
    "    dataset = DataClass(split='train', transform=transforms.ToTensor(), download=True, size=img_size)\n",
    "    train_sets.append(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Dataset TissueMNIST of size 28 (tissuemnist)\n",
       "     Number of datapoints: 165466\n",
       "     Root location: C:\\Users\\pasca\\.medmnist\n",
       "     Split: train\n",
       "     Task: multi-class\n",
       "     Number of channels: 1\n",
       "     Meaning of labels: {'0': 'Collecting Duct, Connecting Tubule', '1': 'Distal Convoluted Tubule', '2': 'Glomerular endothelial cells', '3': 'Interstitial endothelial cells', '4': 'Leukocytes', '5': 'Podocytes', '6': 'Proximal Tubule Segments', '7': 'Thick Ascending Limb'}\n",
       "     Number of samples: {'train': 165466, 'val': 23640, 'test': 47280}\n",
       "     Description: We use the BBBC051, available from the Broad Bioimage Benchmark Collection. The dataset contains 236,386 human kidney cortex cells, segmented from 3 reference tissue specimens and organized into 8 categories. We split the source dataset with a ratio of 7:1:2 into training, validation and test set. Each gray-scale image is 32×32×7 pixels, where 7 denotes 7 slices. We take maximum values across the slices and resize them into 28×28 gray-scale images.\n",
       "     License: CC BY 4.0,\n",
       " Dataset OCTMNIST of size 28 (octmnist)\n",
       "     Number of datapoints: 97477\n",
       "     Root location: C:\\Users\\pasca\\.medmnist\n",
       "     Split: train\n",
       "     Task: multi-class\n",
       "     Number of channels: 1\n",
       "     Meaning of labels: {'0': 'choroidal neovascularization', '1': 'diabetic macular edema', '2': 'drusen', '3': 'normal'}\n",
       "     Number of samples: {'train': 97477, 'val': 10832, 'test': 1000}\n",
       "     Description: The OCTMNIST is based on a prior dataset of 109,309 valid optical coherence tomography (OCT) images for retinal diseases. The dataset is comprised of 4 diagnosis categories, leading to a multi-class classification task. We split the source training set with a ratio of 9:1 into training and validation set, and use its source validation set as the test set. The source images are gray-scale, and their sizes are (384−1,536)×(277−512). We center-crop the images and resize them into 1×28×28.\n",
       "     License: CC BY 4.0,\n",
       " Dataset OrganAMNIST of size 28 (organamnist)\n",
       "     Number of datapoints: 34561\n",
       "     Root location: C:\\Users\\pasca\\.medmnist\n",
       "     Split: train\n",
       "     Task: multi-class\n",
       "     Number of channels: 1\n",
       "     Meaning of labels: {'0': 'bladder', '1': 'femur-left', '2': 'femur-right', '3': 'heart', '4': 'kidney-left', '5': 'kidney-right', '6': 'liver', '7': 'lung-left', '8': 'lung-right', '9': 'pancreas', '10': 'spleen'}\n",
       "     Number of samples: {'train': 34561, 'val': 6491, 'test': 17778}\n",
       "     Description: The OrganAMNIST is based on 3D computed tomography (CT) images from Liver Tumor Segmentation Benchmark (LiTS). It is renamed from OrganMNIST_Axial (in MedMNIST v1) for simplicity. We use bounding-box annotations of 11 body organs from another study to obtain the organ labels. Hounsfield-Unit (HU) of the 3D images are transformed into gray-scale with an abdominal window. We crop 2D images from the center slices of the 3D bounding boxes in axial views (planes). The images are resized into 1×28×28 to perform multi-class classification of 11 body organs. 115 and 16 CT scans from the source training set are used as training and validation set, respectively. The 70 CT scans from the source test set are treated as the test set.\n",
       "     License: CC BY 4.0]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 41,  48,  36, ...,  42,  39,  35],\n",
       "        [ 41,  44,  33, ...,  45,  45,  41],\n",
       "        [ 43,  39,  28, ...,  41,  45,  42],\n",
       "        ...,\n",
       "        [ 14,  22,  60, ...,  11,  13,  14],\n",
       "        [ 10,  22,  63, ...,   9,  11,  12],\n",
       "        [  8,  18,  55, ...,   9,  10,  12]],\n",
       "\n",
       "       [[  3,   6,   8, ...,   7,   6,   6],\n",
       "        [  4,   6,   8, ...,   7,   6,   5],\n",
       "        [  3,   5,   6, ...,   5,   4,   4],\n",
       "        ...,\n",
       "        [ 18,  17,  16, ...,  22,  19,  17],\n",
       "        [ 18,  17,  16, ...,  22,  20,  18],\n",
       "        [ 18,  17,  16, ...,  21,  20,  20]],\n",
       "\n",
       "       [[ 62,  76,  99, ...,  18,  16,  16],\n",
       "        [ 78,  84,  96, ...,  18,  15,  13],\n",
       "        [110,  98,  95, ...,  20,  16,  13],\n",
       "        ...,\n",
       "        [ 11,  12,  11, ...,   2,   2,   2],\n",
       "        [ 11,  12,  11, ...,   2,   2,   2],\n",
       "        [ 11,  12,  11, ...,   2,   2,   2]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[188, 150, 103, ...,  22,  24,  25],\n",
       "        [171, 112,  72, ...,  24,  18,  14],\n",
       "        [152,  88,  73, ...,  21,  18,  17],\n",
       "        ...,\n",
       "        [ 14,  14,  14, ...,  95,  68,  40],\n",
       "        [ 14,  14,  14, ...,  76,  54,  32],\n",
       "        [ 14,  14,  14, ...,  51,  35,  16]],\n",
       "\n",
       "       [[ 59,  56,  48, ...,  44,  35,  27],\n",
       "        [ 59,  56,  46, ...,  37,  23,  14],\n",
       "        [ 50,  48,  38, ...,  33,  15,   7],\n",
       "        ...,\n",
       "        [  9,  11,  10, ...,   8,   8,  12],\n",
       "        [  9,  11,  10, ...,  11,  10,  14],\n",
       "        [  9,  11,  10, ...,  12,  11,  15]],\n",
       "\n",
       "       [[ 10,  11,  11, ...,  22,  21,  20],\n",
       "        [ 13,  12,  12, ...,  18,  17,  16],\n",
       "        [ 14,  14,  13, ...,  20,  19,  19],\n",
       "        ...,\n",
       "        [ 21,  21,  26, ...,  19,  15,  13],\n",
       "        [ 22,  21,  25, ...,  17,  13,  11],\n",
       "        [ 24,  22,  24, ...,  16,  12,  10]]], dtype=uint8)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_sets[0].imgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "165466"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_sets[0].imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import ConcatDataset\n",
    "\n",
    "train_set = ConcatDataset(train_sets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of datasets in ConcatDataset: 3\n",
      "Total number of samples in ConcatDataset: 297504\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of datasets in ConcatDataset:\", len(train_set.datasets))\n",
    "print(\"Total number of samples in ConcatDataset:\", len(train_set))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels from the first dataset: [[0]\n",
      " [0]\n",
      " [6]\n",
      " ...\n",
      " [2]\n",
      " [1]\n",
      " [6]]\n"
     ]
    }
   ],
   "source": [
    "# Retrieve labels from the first dataset in the train_sets list\n",
    "labels = train_sets[0].labels\n",
    "print(\"Labels from the first dataset:\", labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels for dataset 1: [[0]\n",
      " [0]\n",
      " [6]\n",
      " ...\n",
      " [2]\n",
      " [1]\n",
      " [6]]\n",
      "Labels for dataset 2: [[0]\n",
      " [3]\n",
      " [3]\n",
      " ...\n",
      " [0]\n",
      " [3]\n",
      " [0]]\n",
      "Labels for dataset 3: [[6]\n",
      " [8]\n",
      " [5]\n",
      " ...\n",
      " [0]\n",
      " [8]\n",
      " [8]]\n"
     ]
    }
   ],
   "source": [
    "for i, dataset in enumerate(train_sets):\n",
    "    print(f\"Labels for dataset {i+1}:\", dataset.labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vae_medmnist.data.accumulated_dataset import AccumulatedMedMNIST\n",
    "\n",
    "dataloader = AccumulatedMedMNIST(datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:vae_medmnist.data.accumulated_dataset:Setting up AccumulatedMedMNIST with ['tissuemnist', 'octmnist', 'organamnist'] datasets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using downloaded and verified file: C:\\Users\\pasca\\.medmnist\\tissuemnist.npz\n",
      "Using downloaded and verified file: C:\\Users\\pasca\\.medmnist\\tissuemnist.npz\n",
      "Using downloaded and verified file: C:\\Users\\pasca\\.medmnist\\tissuemnist.npz\n",
      "Using downloaded and verified file: C:\\Users\\pasca\\.medmnist\\octmnist.npz\n",
      "Using downloaded and verified file: C:\\Users\\pasca\\.medmnist\\octmnist.npz\n",
      "Using downloaded and verified file: C:\\Users\\pasca\\.medmnist\\octmnist.npz\n",
      "Using downloaded and verified file: C:\\Users\\pasca\\.medmnist\\organamnist.npz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:vae_medmnist.data.accumulated_dataset:Combined train dataset: <torch.utils.data.dataset.ConcatDataset object at 0x000001ADF4670510>\n",
      "INFO:vae_medmnist.data.accumulated_dataset:Combined validation dataset: <torch.utils.data.dataset.ConcatDataset object at 0x000001ADF3F4D250>\n",
      "INFO:vae_medmnist.data.accumulated_dataset:Combined test dataset: <torch.utils.data.dataset.ConcatDataset object at 0x000001ADF460A0D0>\n",
      "INFO:vae_medmnist.data.accumulated_dataset:Number of channels: {1}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using downloaded and verified file: C:\\Users\\pasca\\.medmnist\\organamnist.npz\n",
      "Using downloaded and verified file: C:\\Users\\pasca\\.medmnist\\organamnist.npz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:vae_medmnist.data.accumulated_dataset:Number of classes: 23\n",
      "INFO:vae_medmnist.data.accumulated_dataset:Number of samples: {'train': 297504, 'val': 40963, 'test': 66058}\n"
     ]
    }
   ],
   "source": [
    "dataloader.setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, dataset in enumerate(dataloader.combined_train):\n",
    "    print(f\"Labels for dataset {i+1}:\", dataset.labels)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
